{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595839500178",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 PyTorch 基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 使用 Numpy 实现机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) 导入需要的库\n",
    "import numpy as np\n",
    "# %matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 2) 生成输入数据 x 及目标数据 y\n",
    "# 设置随机数种子，生成同一份数据，以便用多种方法进行比较\n",
    "np.random.seed(100)\n",
    "x = np.linspace(-1, 1, 100).reshape(100, 1)\n",
    "y = 3*np.power(x, 2) +2 + 0.2*np.random.rand(x.size).reshape(100,1)\n",
    "\n",
    "# 3) 查看 x,y 数据分布情况\n",
    "# 画图\n",
    "# plt.scatter(x, y)\n",
    "# plt.show()\n",
    "\n",
    "# 4) 初始化权重参数\n",
    "# 随机初始化参数\n",
    "w1 = np.random.rand(1, 1)\n",
    "b1 = np.random.rand(1, 1)\n",
    "\n",
    "# 5) 训练模型\n",
    "lr = 0.001\n",
    "\n",
    "for i in range(800):\n",
    "    y_pred = np.power(x,2) * w1 + b1\n",
    "\n",
    "    loss = 0.5 * (y_pred - y) ** 2\n",
    "    loss = loss.sum()\n",
    "\n",
    "    grad_w = np.sum((y_pred - y) * np.power(x, 2))\n",
    "    grad_b = np.sum((y_pred - y))\n",
    "\n",
    "    w1 -= grad_w * lr\n",
    "    b1 -= grad_b * lr\n",
    "\n",
    "    # print(loss)\n",
    "print(w1,b1)\n",
    "plt.plot(x, y_pred, 'r-', label='predict')\n",
    "plt.scatter(x, y, color='blue', marker='o', label='true')\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(2, 6)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 使用 Tensor 及 Autograd 实现机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) 导入需要的库\n",
    "import torch as t\n",
    "# %matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 2) 生成输入数据 x 及目标数据 y\n",
    "t.manual_seed(100)\n",
    "dtype = t.float\n",
    "# 生成 x 坐标数据，x 为 tensor，需要把 x 的形状转换为 100x1\n",
    "x = t.unsqueeze(t.linspace(-1, 1, 100), dim=1)\n",
    "# 生成 y 坐标数据，y 为 tensor，形状为 100x1，另加上一些噪声\n",
    "y = 3 * x.pow(2) + 2 + 0.2 * t.rand(x.size(),requires_grad=True).view(100, 1)\n",
    "\n",
    "# 画图，把 tensor 数据转换为 numpy 数据\n",
    "plt.scatter(x.detach().numpy(), y.detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "# 3) 初始化权重参数\n",
    "# 随机初始化参数，参数 w、b 为需要学习的，故需 requires_grad=True\n",
    "w = t.randn(1, 1, dtype = dtype, requires_grad=True)\n",
    "b = t.zeros(1, 1, dtype = dtype, requires_grad=True)\n",
    "\n",
    "# 4) 训练模型\n",
    "lr = 0.001\n",
    "\n",
    "for ii in range(80):\n",
    "    y_pred = x.pow(2).mm(w) + b\n",
    "    loss = 0.5 * (y_pred - y) ** 2\n",
    "    loss = loss.sum()\n",
    "\n",
    "    # 自动计算梯度，梯度存放在 grad 属性中\n",
    "    loss.backward(retain_graph=True)\n",
    "    # loss.backward()\n",
    "\n",
    "    # 手动更新参数，需要用 torch.no_grad()，使上下文环境中切断自动求导的计算\n",
    "    with t.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "\n",
    "    # 梯度清零\n",
    "        w1.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "# 5) 可视化训练结果\n",
    "plt.plot(x.detach().numpy(), y_pred.detach().numpy(), 'r-', label='preddice') # Predict\n",
    "plt.scatter(x.detach().numpy(), y.detach().numpy(), color='blue', marker='o', label='true') # True data\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(2, 6)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 PyTorch 神经网络工具箱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入必要的模块\n",
    "import numpy as np\n",
    "import torch\n",
    "# 导入 PyTorch 内置的 mnist 数据\n",
    "from torchvision.datasets import mnist\n",
    "# 导入预处理模块\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# 导入 nn 及优化器\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义一些超参数\n",
    "# 定义一些超参数\n",
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "learning_rate = 0.01\n",
    "num_epoches = 20\n",
    "lr = 0.01\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 下载数据并对数据进行预处理 \n",
    "# 定义预处理函数，这些预处理一次放在 Compose 函数中\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "# 下载数据，并对数据进行预处理\n",
    "train_dataset = mnist.MNIST('./data', train=True, transform=transform, download=False)\n",
    "test_dataset = mnist.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "# dataloader 是一个可迭代对象，可以使用迭代器一样使用\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 可视化源数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 构建网络\n",
    "class Net(nn.Module):\n",
    "    '''\n",
    "    使用 sequential 构建网络，Sequential() 函数的功能是将网络的层组合到一起\n",
    "    '''\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 实例化网络\n",
    "# 检查是否有可用的 GPU，有则使用，否则使用 CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs\")\n",
    "#         # dim = 0[20, xxx] --> [10, ...], [10, ...] on 2GPUs\n",
    "#         model = nn.DataParallel(model)\n",
    "# 实例化网络\n",
    "model = Net(28 * 28, 300, 100, 10)\n",
    "model.to(device)\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 训练模型\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs4', comment='train-loss')\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    # 动态修改参数学习率\n",
    "    if epoch%5 == 0:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.1\n",
    "    for img, label in train_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        # 前向传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 记录误差\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 计算分类的准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        train_acc += acc\n",
    "    \n",
    "    losses.append(train_loss / len(train_loader))\n",
    "    acces.append(train_acc / len(train_loader))\n",
    "    # 在测试集上验证效果\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    # 将模型改为预测模式\n",
    "    model.eval()\n",
    "    for img, label in test_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        # 记录误差\n",
    "        eval_loss += loss.item()\n",
    "        # 记录准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        eval_acc += acc\n",
    "\n",
    "    eval_losses.append(eval_loss / len(test_loader))\n",
    "    eval_acces.append(eval_acc / len(test_loader))\n",
    "    print('epoch: {}, Train Loss: {:.4f}, Train Acc: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.4f}' \n",
    "          .format(epoch, train_loss/len(train_loader), train_acc/len(train_loader), \n",
    "                  eval_loss/len(test_loader),eval_acc/len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 可视化训练及测试损失值\n",
    "plt.title('trainloss')\n",
    "plt.plot(np.arange(len(losses)), losses)\n",
    "plt.legend(['Train Loss'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 动态修改学习率参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoches):\n",
    "# 动态修改参数学习率\n",
    "    if epoch%5 == 0:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.1\n",
    "        print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 优化器比较\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 导入需要的模块\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# 超参数\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 生成数据\n",
    "# 生成训练数据\n",
    "# torch.unsqueeze() 的作用是将一维变为二维，torch 只能处理二维的数据\n",
    "x = torch.unsqueeze(torch.linspace(-1, 1, 1000), dim=1)\n",
    "# 0.1 * torch.normal(x.size()) 增加噪点\n",
    "y = x.pow(2) + 0.1 * torch.normal(torch.zeros(*x.size()))\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "# 得到一个代批量的生成器\n",
    "loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 构建神经网络\n",
    "class Net(torch.nn.Module):\n",
    "    # 初始化\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(1, 20)\n",
    "        self.predict = torch.nn.Linear(20, 1)\n",
    "    # 前向传递\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 使用多种优化器\n",
    "net_SGD      = Net()\n",
    "net_Momentum = Net()\n",
    "net_RMSProp  = Net()\n",
    "net_Adam     = Net()\n",
    "\n",
    "nets = [net_SGD, net_Momentum, net_RMSProp, net_Adam]\n",
    "\n",
    "opt_SGD         = torch.optim.SGD(net_SGD.parameters(), lr=LR)\n",
    "opt_Momentum    = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.9)\n",
    "opt_RMSProp     = torch.optim.RMSprop(net_RMSProp.parameters(), lr=LR, alpha=0.9)\n",
    "opt_Adam        = torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(0.9, 0.99))\n",
    "optimizers = [opt_SGD, opt_Momentum, opt_RMSProp, opt_Adam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 训练模型\n",
    "loss_func = torch.nn.MSELoss()\n",
    "loss_his = [[], [], [], []]     # 记录损失\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        for net, opt, l_his in zip(nets, optimizers, loss_his):\n",
    "            output = net(batch_x) # Get output for every net\n",
    "            loss = loss_func(output, batch_y) # Compute loss for every net\n",
    "            opt.zero_grad() # Clear gradients for next train\n",
    "            loss.backward() # Backpropagation, compute gradients\n",
    "            opt.step() # Apply gradients\n",
    "            l_his.append(loss.data.numpy()) # Loss recoder\n",
    "labels = ['SGD', 'Momentum', 'RMSProp', 'Adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 可视化结构\n",
    "for i, l_his in enumerate(loss_his):\n",
    "    plt.plot(l_his, label=labels[i])\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim((0, 0.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 PyTorch数据处理工具箱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 utils.data 简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 导入需要的模块\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 定义获取数据集的类\n",
    "# 该类继承基类 Dataset，自定义一个数据集及对应标签\n",
    "class TestDataset(data.Dataset): # 继承 Dataset\n",
    "    def __init__(self):\n",
    "        self.Data = np.asarray([[1,2], [3,4], [2,1], [3,4], [4,5]]) # 一些由 2 维向量表示的数据集\n",
    "        self.Label = np.asarray([0, 1, 0, 1, 2]) # 这是数据集对应的标签\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 把 numpy 转换为 Tensor\n",
    "        txt = torch.from_numpy(self.Data[index])\n",
    "        label = torch.tensor(self.Label[index])\n",
    "        return txt,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "    test_loader = data.DataLoader(Test,batch_size=2,shuffle=False,num_workers=2)\n",
    "    for i,traindata in enumerate(test_loader):\n",
    "        print('i:',i)\n",
    "        Data,Label=traindata\n",
    "        print('data:',Data)\n",
    "        print('Label:',Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(Test,batch_size=2,shuffle=False,num_workers=2)\n",
    "dataiter = iter(test_loader)\n",
    "imgs, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 torchvision 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torchvision import datasets loader = datasets.ImageFolder(r'D:\\Users\\Administrator\\Desktop\\PythonDLbasedonPytorch\\data\\torchvision_data') loader = data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "my_trans = transforms.Compose([\n",
    "    transforms.RandomSizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_data = datasets.ImageFolder(r'D:\\Users\\Administrator\\Desktop\\PythonDLbasedonPytorch\\data\\torchvision_data', transform=my_trans)\n",
    "train_loader = data.DataLoader(train_data, batch_size=8, shuffle=True,)\n",
    "\n",
    "for i_batch, img in enumerate(train_loader):\n",
    "    if i_batch == 0:\n",
    "        print(img[1])\n",
    "        fig = plt.figure()\n",
    "        grid = utils.make_grid(img[0])\n",
    "        plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        utils.save_image(grid, 'test01.png')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开 test01.png 文件\n",
    "from PIL import Image\n",
    "Image.open('test01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 可视化工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 tensorboardX 简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "# 实例化 SummaryWriter，并指明日志存放路径。在当前目录没有 logs 目录将自动创建。\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "# 调用实例\n",
    "writer.add_xxx()\n",
    "# 关闭 writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 用 tensorboardX 可视化神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "module functions cannot set METH_CLASS or METH_STATIC",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-e9cff235ebcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1) 导入需要的模块\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;31m# See Note [Global dependencies]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[0m_load_global_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[1;31mValueError\u001b[0m: module functions cannot set METH_CLASS or METH_STATIC"
     ]
    }
   ],
   "source": [
    "# 1) 导入需要的模块\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 构建神经网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.bn = nn.BatchNorm2d(20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.conv1(x), 2)\n",
    "        x = F.relu(x) + F.relu(-x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.bn(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3) 把模型保存为 graph\n",
    "# 定义输入\n",
    "input = torch.rand(32, 1, 28, 28)\n",
    "# 实例化神经网络\n",
    "model = Net()\n",
    "# 将 model 保存为 graph\n",
    "with SummaryWriter(log_dir='logs', comment='Net') as w:\n",
    "    w.add_graph(model, (input, ))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 用 tensorboardX 可视化损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "writer = SummaryWriter(log_dir='logs', comment='Linear')\n",
    "np.random.seed(100)\n",
    "x_train = np.linspace(-1, 1, 100).reshape(100, 1)\n",
    "y_train = 3 * np.power(x_train, 2) + 2 + 0.2 * np.random.rand(x_train.size).reshape(100, 1)\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    inputs = torch.from_numpy(x_train).type(dtype)\n",
    "    targets = torch.from_numpy(y_train).type(dtype)\n",
    "\n",
    "    output = model(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 保存 loss 的数据与 epoch 数值\n",
    "    writer.add_scalar('训练损失值', loss, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 用 tensorboardX 可视化特征图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "writer = SummaryWriter(log_dir='logs', comment='feature map')\n",
    "\n",
    "img_grid = vutils.make_grid(x, normalize=True, scale_each=True, nrow=2)\n",
    "net.eval()\n",
    "for name, layer in net._modeles.items():\n",
    "    # 为 fc 层预处理 x\n",
    "    x = x.view(x.size(0), -1) if \"fc\" in name else x\n",
    "    print(x.size())\n",
    "\n",
    "    x = layer(x)\n",
    "    print(f'{name}')\n",
    "\n",
    "    # 查看卷积层的特征图\n",
    "    if 'layer' in name or 'conv' in name:\n",
    "        x1 = x.transpose(0, 1) # C,B,H,W ---> B,C,H,W\n",
    "        # normalize 进行归一化处理\n",
    "        img_grid = vutils.make_grid(x1, normalize=True, scale_each=True, nrow=4)\n",
    "        writer.add_image(f'{name}_feature_maps', img_grid, global_step=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 机器学习基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 视觉处理基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 卷积神经网络简介\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 36, 3, 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(1296, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 36*6*6)\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x\n",
    "net = CNNNet()\n",
    "# net = net.to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=32x32 at 0x173C9EC4D00>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAC1ElEQVR4nO2X30tTYRjHP+7stKPbzPkLZWabaxbBiNEugrrSCCIpSKgEoS4CAy8KuqgLwQQv7FIoKPAyGAliQdGFZf+AJalEMqZjuhJ1uXTTM7dpF+Zx82wxamkX+16+z/M+z+f9Pue8h1Ngt9dvso/S7GfzPACANhdFbFc6KbY6AVgYecXsuz5VjiAZsLd0U1hpAWB5ehRvf1duALz9XQpIJlWfvgbAWG8rCTmsrO/ZCHRlZsL+iZTmkDSCmsabVLialID/zWOCY0NAZvuylSAZEPUmosGAKqYFKLY6KT7i4vPTW0RDc6oky8W7xCJLfHl4R4GpabyZdtbJ0pVUYW/tQdSXAFBYaaHC1cRGLMr0YA/L06M7Doh6E4ZahwpAV1KFqDcxPdgDQEIOs/DhNRUnLyBIBpWlyYqG5ph4dEOBDvsnVNBa2LJ09m0ftefbqT3fztq8D4+7g4QcRmeqRmeq5njbk5SNa/O+354+WykOBMeGlJnbrnRib+nG4+4AIBZZwvv8Qdrx/K3SvgXJD0vkm4eNdZmac205bw6/HNj9BsQiITzP7ivz9bg7sLd047z3QsnZvnB2P2hYnVS4mjJeSLtVkP8a5gHyAHmA/wrA2VxHw20HZRbjP2mmlQROXa/H7ChND5DLwunkuHCYaDhOYPz7zt7khNGBqVzwpJXZUYqxUmLE7U1ZL7Db6zfLLEZOXLIgiBqikRgjbi+roegWoSTgvGzl6/h3bGeq0OnFlBxncx3lVvXI/B8WmXwfUGq4rtqY+biYenpJ2HIg6FthuHecMouRY2fNqmKCqOFog5lPL338mFvFddXGIWc5k+8DjA5MZWywrYNVRQiihqWZSMp6XE6g0UpCVhZODgcI+laIywmW/BGKSnVZ7QOQjCKJ2AbrclwV08TlRNaF/lSG8sKMsT25B8KLa/8WIC4niIbjVNaXpI3LKzEEUcMBSf0j9hOCYhMsIGIa0QAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# 导入图片查看维度\n",
    "from PIL import Image\n",
    "im = Image.open(r'd:\\Users\\Administrator\\Desktop\\test.png')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "# 3) 把模型保存为 graph\n",
    "# 定义输入\n",
    "input = torch.rand(32*32, 3)\n",
    "# 实例化神经网络\n",
    "# 将 model 保存为 graph\n",
    "with SummaryWriter(log_dir='logs', comment='Net') as w:\n",
    "    w.add_graph(net, (input, ))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 PyTorch 实现 CIFAR-10 多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 自然语言处理基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 生成式深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 用变分自编码器生成图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义重构损失函数及 KL 散度\n",
    "reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "# 两者相加得总损失\n",
    "loss = reconst_loss + kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 导入需要的包\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 定义一些超参数\n",
    "image_size       = 784\n",
    "h_dim            = 400\n",
    "z_dim            = 20\n",
    "num_epochs       = 30\n",
    "batch_size       = 128\n",
    "learning_rate    = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 对数据集进行预处理\n",
    "# 下载 MNIST 训练集\n",
    "dataset = torchvision.datasets.MNIST(root='../data', train=True, transform=transforms.ToTensor(), download=False)\n",
    "# 数据加载\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 构建 AVE 模型，主要由 Encode 和 Decode 两部分组成\n",
    "# 定义 AVE 模型\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "# 用 mu，log_var 生成一个潜在空间点 z，mu，log_var 为两个统计参数，我们假设这个建设分布能生成图像\n",
    "def reparameterize(self, mu, log_var):\n",
    "    std = torch.exp(log_var/2)\n",
    "    eps = torch.rand_like(std)\n",
    "    return mu+eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 选择 GPU 及优化器\n",
    "# 设置 PyTorch 在哪块 GPU 上运行，这里假设使用序号为 0 的这块 GPU\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 训练模型，同时保存原图像与随机生成的图像\n",
    "with torch.no_grad():\n",
    "    # 保存采样图像，及潜在向量 Z 通过解码器生成的新图像\n",
    "    z = torch.randn(batch_size, z_dim).to(device)\n",
    "    out = model.decode(z).view(-1, 1, 28, 28)\n",
    "    save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "    # 保存重构图像，即原图像通过解码器生成的图像\n",
    "    out, _, _ = model(x)\n",
    "    x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "    save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 展示原图像及重构图像\n",
    "reconsPath = './ave_samples/reconst-30.png'\n",
    "Image = mpimg.imread(reconsPath)\n",
    "plt.imshow(Image) # 显示图像\n",
    "plt.asix('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) 显示由潜在空间点 Z 生成的新图像\n",
    "genPath = './ave_samples/sampled-30.png'\n",
    "Image = mpimg.imread(genPath)\n",
    "plt.imshow(Image) # 显示图像\n",
    "plt.asix('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 GAN 简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判断器对真图像的损失函数\n",
    "outputs = D(images)\n",
    "d_loss_real = criterion(outputs, real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器对假图像（即由潜在空间点生成的图像）的损失函数\n",
    "z = torch.randn(batch_size, latent_size).to(device)\n",
    "fake_images = G(z)\n",
    "outputs = D(fake_images)\n",
    "d_loss_fake = criterion(outputs, fake_labels)\n",
    "fake_score = outputs\n",
    "# 得到判别器总的损失函数\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(batch_size, latent_size).to(device)\n",
    "fake_images = G(z)\n",
    "outputs = D(fake_images)\n",
    "\n",
    "g_loss = criterion(outputs, real_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 用 GAN 生成图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 判别器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建判断器\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size), \n",
    "    nn.LeakyReLU(0.2), \n",
    "    nn.Linear(hidden_size, hidden_size), \n",
    "    nn.LeakyReLU(0.2), \n",
    "    nn.Linear(hidden_size, 1), \n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建生成器\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(hidden_size, hidden_size), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(hidden_size, image_size), \n",
    "    nn.tanh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "\n",
    "        # 定义图像是真或假的标签\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        #                训练判别器\n",
    "        # ----------------------------------------------\n",
    "        \n",
    "        # 定义判别器对真图像的损失函数\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "\n",
    "        # 定义判别器对假图像（即由潜在空间点生成的图像）的损失函数\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "\n",
    "        # 对生成器、判别器的梯度清零\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # ------------------------------------------------\n",
    "        #                训练生成器\n",
    "        # ------------------------------------------------\n",
    "\n",
    "        # 定义生成器对假图像的损失函数，这里我们要求判别器生成的图像越来越像真图片\n",
    "        # 故损失函数中的标签改为真图像的标签，即希望生成的假图像，越来越靠近真图像\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # 对生成器、判别器的梯度清零，进行反向传播及运行生成器的优化器\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'.format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))\n",
    "        # 保存真图像\n",
    "        if (epoch+1) == 1:\n",
    "            images = images.reshape(images.size(0), 1, 28, 28)\n",
    "            save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "        # 保存假图像\n",
    "        fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "            save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    \n",
    "    # 保存模型\n",
    "    torch.save(G.state_dict(), 'G.ckpt')\n",
    "    torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconsPath = './gan_samples/fake_images-200.png'\n",
    "Image = mpimg.imread(reconsPath)\n",
    "plt.imshow(Image) # 显示图片\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}